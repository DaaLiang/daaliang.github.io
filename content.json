{"pages":[{"title":"tags","text":"","link":"/tags/index.html"},{"title":"categories","text":"","link":"/categories/index.html"},{"title":"about","text":"","link":"/about/index.html"}],"posts":[{"title":"100个句子记完7000个托福单词 句子部分(中文)","text":"要好好学英语…把这本书的句子部分背一遍，在博客把中分英文分开打以便方便对照记忆。 理论在本质上是对人们构想的现实的一种抽象和符号化的表示。 受当代灌溉设施之赐，在原来只有仙人掌和灌木蒿才能生存的地方，现在农作物也生长茂盛。 人类学家已经发现，恐惧、快乐、悲伤和惊奇会反映在面部表情上，这在全人类是共通的。 1986年看见哈雷彗星的千百万人当中，有多少人能够长寿到足以目睹它在21世纪的回归呢？ 一个地方的人口越多，其对水、交通和垃圾处理的需求就会越大。 完美搭配的珍珠串成一条项链，能带来比单颗售卖高得多的价钱。 机械计时器的发展促使人们寻求更精确的日晷，以便校准机械计时器。 对地球重力的研究表明，当被施加不寻常的重力时，地球的地壳和地幔会发生变形。 &lt;待续…&gt;","link":"/2019/02/26/100个句子记完7000个托福单词-句子部分-中文/"},{"title":"100个句子记完7000个托福单词 句子部分(英文)","text":"English part. Essentially, a theory is an abstract, symbolic representation of what is conceived to be reality. Thanks to modern irrigation, crops now grow abundantly in areas where once nothing but cacti and sagebrush could live. Ahthropologists have discovered that fear, happiness, sadness, and surprise are universally reflected in facial expression. Of the millions who saw Haley’s Comet in 1986, how many people will live long enough to see it return in the twenty-first century. The greater the population there is in a locality, the greater the need there is for water, transportation, and disposal of refuse. Perfectly matched pearls, strung into a necklace, bring a far higher price than the same pearls sold individually. The development of mechanical timepieces spurred the search for more accurate sundials with which to regulate them. Studies of the gravity field of the Earth indicate that its crust and mantle yield when unusual weight is placed on them.","link":"/2019/02/26/100个句子记完7000个托福单词-句子部分-英文/"},{"title":"Hello World","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new \"My New Post\" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","link":"/2015/01/26/hello-world/"},{"title":"TensorFlow实战Google深度学习框架 笔记 第二、三章","text":"第二章 TensorFlow 环境搭建简单示例代码：12345678import tensorflow as tfa = tf.constant([1.0, 2.0], name=\"a\")b = tf.constant([2.0, 3.0], name=\"b\")result = a + bsess = tf.Session()sess.run(result)---输出---array([3., 5.], dtype=float32) 第三章 TensorFlow 入门3.1 计算图 系统默认维护一个计算图,通过tf.get_default_graph获取当前默认计算图。 通过a.graph查看张量a所属计算图。示例： 123print(a.graph is tf.get_default_graph())---输出---True 在不同计算图上定义和使用变量 123456789101112131415161718192021222324252627import tensorflow as tfg1 = tf.Graph()with g1.as_default(): #g1中定义\"v\", 设置为0。 v = tf.get_variable( \"v\", initializer = tf.zeros_initializer(shape = [1]) )g2 = tf.Graph()with g2.as_default(): #g2中定义\"v\", 设置为1。 v = tf.get_variable( \"v\", initializer = tf.ones_initializer(shape = [1]) )with tf.Session(graph=g1) as sess: tf.global_variables_initializer().run() with tf.variable_scope(\"\", reuse=True): print(sess.run(tf.get_variable(\"v\"))) #g1中\"v\"输出0。 with tf.Session(graph=g2) as sess: tf.global_variables_initializer().run() with tf.variable_scope(\"\", reuse=True): print(sess.run(tf.get_variable(\"v\"))) #g2中\"v\"输出1。 对计算图指定计算设备 1234g = tf.Graph()# 指定计算运行的设备。with g.device('/gpu:0'): result = a + b 在一个计算图中，可以通过集合(collection)管理不同类别的资源。通过tf.add_to_collection函数可以将资源加入一个或多个集合中，然后通过tf.get_collection获取一个集合里面的所有资源。这里的资源可以是张量、变量或者运行TensorFlow 程序所需要的队列资源,等等。TensorFlow 也自动管理了一些最常用的集合: 集合名称 集合内容 使用场景 tf.GraphKeys.VARIABLES 所有变量 持久化 TensorFlow 模型 tf.GraphKeys.TRAINABLE_VARIABLES 可学习的变量（一般指神经网络中的参数） 模型训练、生成模型可视化内容 tf.GraphKeys.SUMMARIES 日志生成相关的张量 TensorFlow 计算可视化 tf.GraphKeys.QUEUE_RUNNERS 处理输入的QueueRunner 输入处理 tf.GraphKeys.MOVING_AVERAGE_VARIABLES 所有计算了滑动平均值的变量 计算变量的滑动平均值 3.2 张量张量可以理解为多维数组，一阶张量为标量(scalar)，二阶张量为向量(vector)，n阶张量可以理解为n维数组。张量不保存数值，保存的是计算数值的过程。12345678import tensorflow as tfa = tf.constant([1.0, 2.0], name=\"a\")b = tf.constant([2.0, 3.0], name=\"b\")result = tf.add(a, b, name=\"add\")print result---输出--Tensor(\"add:0\", shape=(2,), dtype=float32) 张量保存了三个属性：名字(name), 维度(shape), 类型(type)。 名字：张量的命名可以通过“node:src_output”的形式来给出。其中 node 为节点的名称，src_output表示当前张量来自节点的第几个输出。上面”add:0”说明result是计算节点”add”输出的第一个结果。 维度：描述张量的维度信息。shape=(2，）说明了result是一个一维数组，这个数组的长度为2。 类型：计算类型需匹配否则报错。例，若将以上代码的a小数点去掉，成为a = tf.constant([1 , 2], name=&quot;a&quot;)则运行报错：ValueError: Tensor conversion requested dtype int32 for Tensor with dtype float32：'Tensor(&quot;b:0&quot;, shape=(2,), dtype=float32)'可以指定a的类型则不会出问题：a = tf.constant([1,2], name=&quot;a&quot;, dtype=tf.float32) TensorFlow支持的14种不同类型：实数(tf.float32, tf.float64), 整数(tf.int8, tf.int16, tf.int32, tf.int64, tf.unit8), 布尔型(tf.bool)和复数(tf.complex64, tf.complex128)。通过result.get_shape函数可以获取结果张量的维度信息。张量没有存储计算结果，但是可以通过会话获得，例如通过tf.Session().run(result)获得result结果。 3.3 会话(TensorFlow运行模型)使用会话的方式： 手动释放： 1234567# 创建一个会话。sess = tf.Session()# 使用这个创建好的会话来得到关心的运算的结果。比如可以调用sess.run(result),# 来得到 3.1 节样例中张量 result 的取值。sess.run(...)# 关闭会话使得本次运行巾使用到的资源可以被释放。sess.close() 自动释放: 123456# 创建一个会话，并通过 Python 中的上下文管理器来管理这个会话。with tf.Session() as sess:# 使用创建好的会话来计算关心的结果。sess.run (...)# 不需要再调用\"Session.close()\"函数来关闭会话，# 当上下文退出时会话关闭和资源释放也自动完成了。 TensorFlow 不会自动生成默认的会话，而是需要手动指定。当默认的会话被指定之后可以通过tf.Tensor.eval 函数来计算一个张量的取值 。123sess = tf.Session()with sess.as default():print(result. eval()) 以下代码功能相同1234sess = tf.Session()# 以下两个命令有相同的功能。print(sess.run(result))print(result.eval(session=sess)) 使用tf.lnteractiveSession函数会自动将生成的会话注册为默认会话。123sess = tf.InteractiveSession()prirnt(result. eval())sess.close() 以上，无论使用哪种方法都可以通过 ConfigProto Protocol BufferCD来配置需要生成的会话，方法： 123config = tf.ConfigProto(allow soft placement=True, log_device_placement=True)sessl = tf.InteractiveSession(config=config)sess2 = tf.Session(config=config) ConfigProto常用配置参数: allow_soft_placement:这是一个布尔型的参数，默认为False，当它为 True 时，在以下任意一个条件成立时， GPU 上的运算可以放到 CPU 上进行 ： 运算无法在 GPU 上执行。 没有 GPU 资源 (比如运算被指定在第二个 GPU 上运行，但是机器只有一个 GPU)。 运算输入包含对 CPU 计算结果的引用。 log_device_placement:这也是一个布尔型的参数，当它为 True 时日志中将会记录每个节点被安排在哪个设备上以方便调试。生产环境中设置为 False 可以减少日志量。 3.4 TensorFlow实现神经网络矩阵乘法：12a = tf.matmul(x, w1)y = tf.matmul(a, w2) 变量初始化12#产生一个 2×3 的矩阵，矩阵中的元素是均值为 0，标准差为 2 的随机数。可以通过参数 mean 来指定平均值，默认为0。weights = tf.Variable(tf.random_normal([2, 3]), stddev=2)) TensorFlow 随机数生成函数表 函数名称 随机数分布 主要参数 tf.random_normal 正态分布 平均值、标准差、取值类型 tf.truncated_normal 正态分布，但如果随机出来的值偏离平均值超过2个标准差就重新随机 平均值、标准差、取值类型 tf.random_uniform 均匀分布 最小、最大取值，取值类型 tf.random_gamma Gamma分布 形状参数alpha、尺度参数 beta、取值类型 TensorFlow常数生成函数表 函数名称 功能 样例 tf.zeros 产生全 0 的数组 tf.zeros([2, 3], int32) -&gt; [[0, 0, 0], [0, 0, 0]] tf.ones 产生全 1 的数组 tf.ones([2, 3], int32) -&gt; [[1, 1, 1], [1, 1, 1]] tf.fill 产生一个全部为给定数字的数组 tf.fill([2, 3], 9) -&gt; [[9, 9, 9], [9, 9, 9]] tf.constant 产生一个给定值的常量 tf.constant([1, 2, 3]) -&gt; [1, 2, 3] 一些以常数初始化数值的方法：123456biases = tf.Variable(tf.zeros([3]))# 生成一个初始值全部为 0 且长度为 3 的变量w2 = tf.Variable(weights.initialized_value())# w2 的初始值被设置成了与 weights 变量相同w3 = tf.Variable(weights.initialized_value() * 2.0)# w3 的初始值则是 weights 初始值的两倍 一个前向传播过程： 123456789101112131415161718import tensorflow as tf# 声明 w1、w2 两个变盘。这里还通过 seed 参数设定了随机种子，# 这样可以保证每次运行得到的结果是一样的。w1 = tf.Variable(tf.random_normal((2, 3), stddev=1, seed=1))w2 = tf.Variable(tf.random_normal((3, 1), stddev=1, seed=1))# 暂时将输入的特征向量定义为一个常量。注意这里 x 是一个 1×2 的矩阵。x = tf.constant([[0.7, 0.9]])# 通过 3.4.2 节描述的前向传播算法获得神经网络的输出。a = tf.matmul(x, w1)y = tf.matmul(a, w2)sess = tf.Session()# 与 3.4.2 中的计算不同，这里不能直接通过 sess.run(y) 来获取 y 的取值，# 因为 w1 和 w2 都还没有运行初始化过程。以下两行分别初始化了 w1 和 w2 两个变量。sess.run(w1.initializer) # 初始化 w1。sess.run(w2.initializer) # 初始化 w2。# 输出[[3.95757794]]。print(sess.run(y))sess.close() 当需要初始化的变量变多，可以使用以下方法初始化：12init_op = tf.global_variables_initializer()sess.run(init_op) 通过 tf.global_variables() 函数可以拿到当前计算图上所有的变量。 可以通过变量声明函数中的 trainable 参数来区分需要优化的参数（比如神经网络中的参数）和其他参数（比如选代的轮数）。如果声明变量时参数 trainable 为 True，那么这个变量将会被加入到GraphKeys.TRAINABLE_VARIABLES 集合。 类似张量，维度（shape)和类型 (type) 也是变量最重要的两个属性，一个变量在构建之后，它的类型就不能再改变了。 1234567w1 = tf.Variable(tf.random_normal([2, 3], stddev=1), name=\"w1\")w2 = tf.Variable(tf.random_normal([2, 3], dtype=tf.float64, stddev=1),name=\"w2\")w1.assign(w2)'''程序将报错：TypeError: Input 'value' of 'Assign' Op has type float64 that does not match type float32 of argument 'ref'. 维度在程序运行中是有可能改变的，但是需要通过设置参数validate_shape=False。 12345678w1 = tf.Variable(tf.random_normal([2, 3], stddev=1), name = \"w1\")w2 = tf.Variable(tf.random_normal([2, 2], stddev=1), name = \"w2\")# 下面这句会报维度不匹配的错误：# ValueError: Dimension 1 in both shapes must be equal, but are 3 and 2# for 'Assign_1' (op: 'Assign') with input shapes: [2, 3], [2, 2].tf.assign(w1, w2)# 这一句可以被成功执行。tf.assign(w1, w2, validate_shape=False) 完整训练模型 placeholder预占用输入数据位置 123x = tf.placeholder(tf.float32, shape = (3, 2), name=\"input\")# 因为 x 在定义时指定了 n 为 3，所以在运行前向传播过程时需要提供 3 个样例数据。print(sess.run(y, feed_dict={x: [[0.7, 0.9), [0.1, 0.4] , [0.5, 0.8]]})) 定义一个简单的损失函数 123456789101112# 使用 sigmoid 函数将 y 转换为 0~1 之间的数值。转换后 y 代表预测是正样本的概率， 1-y 代表# 预测是负样本的概率 。y=tf.sigmoid(y)# 定义损失函数来刻画预测值与真实值的差距。cross_entropy = -tf.reduce_mean(y_ * tf.log(tf.clip_by_value(y, 1e-10, 1.0))+(1-y)*tf.log(tf.clip_by_value (1-y, 1e-10, 1.0)))# 定义学习率，在第 4 章中将更加具体的介绍学习率。learning_rate = 0.001# 定义反向传播算法来优化神经网络中的参数。train_step =\\tf.train.AdamOptimizer(learning_rate) .minimize (cross_entropy) 以上代码中，train_step定义了反向传播优化方法，通常包括三种tf.train.GradientDescentOptimizer、 tf.train.AdamOptimizer和tf.train.MomentumOptimizer。在定义了反向传播算法之后，通过运行 sess.run(train_ step）就可以对所有在 GraphKeys .TRAINABLE_VARIABLES 集合中的变量进行优化，使得在当前 batch 下损失函数更小。 完整样例程序12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788import tensorflow as tf# NumPy 是一个科学计算的工具包，这里通过 NumPy 工具包生成模拟数据集。from numpy.random import RandomState# 定义训练数据 batch 的大小。batch_size = 8# 定义神经网络的参数，这里还是沿用 3.4.2 小节中给出的神经网络结构 。w1 = tf.Variable(tf.random_normal([2, 3], stddev=1 , seed=1))w2 = tf.Variable(tf.random_normal([3, 1], stddev=1 , seed=1))# 在 shape 的一个维度上使用 None 可以方便使用不同的 batch 大小。在训练时需要把数据分# 成比较小的 batch ， 但是在测试时，可以一次性使用全部的数据。当数据集比较小时这样比较# 方便测试，但数据集比较大时，将大量数据放入一个 batch 可能会导致内存溢出。x = tf.placeholder(tf.float32, shape=(None, 2), name = 'x-input')y_ = tf.placeholder(tf.float32, shape=(None, 1), name = 'y-input')# 定义神经网络前向传播的过程。a = tf.matmul (x, w1)y = tf.matmul (a, w2)# 定义损失函数和反向传播的算法。y = tf.sigmoid(y)cross_entropy = -tf.reduce_mean( y_ * tf.log(tf.clip_by_value(y, 1e-10, 1.0))+(1-y)*tf.log(tf.clip_by_value(1 - y, 1e-10, 1.0)))train_step = tf.train.AdamOptimizer(0.001).minimize(cross_entropy)# 通过随机数生成一个模拟数据集。rdm = RandomState(1)dataset_size = 128X = rdm.rand(dataset_size, 2)# 定义规则来给出样本的标签。在这里所有 x1+x2&lt;1 的样例都被认为是正样本（比如零件合格），# 而其他为负样本（比如零件不合格）。和 TensorFlow 游乐场中的表示法不大一样的地方是，# 在这里使用 0 来表示负样本， 1 来表示正样本。大部分解决分类问题的神经网络都会采用# 0 和 1 的表示方法。Y = [[int(x1+x2 &lt; 1)] for (x1, x2) in X]# 创建一个会话来运行 TensorFlow 程序。with tf.Session() as sess: init_op = tf.global_variables_initializer()# 初始化变量。sess.run(init_op)print(sess.run(w1))print(sess.run(w2))'''在训练之前神经网络参数的值：w1 = [[-0.81131822, 1.48459876, 0.06532937][-2.44270396, 0.0992484, 0.59122431]]w2 = [[-0.81131822), [1.48459876], [0.06532937]]'''# 设定训练的轮数。STEPS = 5000for i in range (STEPS): # 每次选取 batch_size 个样本进行训练。 start = (i * batch_size) % dataset_size end = min(start+batch_size, dataset_size) # 通过选取的样本训练神经网络并更新参数。 sess.run(train_step, feed_dict={x:X[start:end], y_:Y[start:end]}) if i % 1000 == 0 : # 每隔一段时间计算在所有数据上的交叉煽并输出。 total_cross_entropy = sess.run(cross_entropy, feed_dict={x:X, y_:Y}) print(\"After %d training step(s), cross entropy on all data is %g\" % (i, total_cross_entropy)) ''' 输出结果 ： After 0 training step (s), cross entropy on all data is 1.89805 After 1000 training step (s), cross entropy on all data is 0.655075 After 2000 training step (s), cross entropy on all data is 0.626172 After 3000 training step (s), cross entropy on all data is 0.615096 After 4000 training step (s), cross entropy on all data is 0.610309 通过这个结果可以发现随着训练的进行，交叉煽是逐渐变小的。交叉熵越小说明 预测的结果和真实的结果差距越小。 '''print(sess.run(w1))print(sess.run(w2))'''在训练之后神经网络参数的值：w1 = [[0.02476984, 0.5694868, 1.69219422][-2.19773483, -0.23668921, 1.11438966]]w2 = [[-0.45544702], [0.49110931], [-0.9811033]]可以发现这两个参数的取值已经发生了变化，这个变化就是训练的结果。它使得这个神经网络能更好地拟合提供的训练数据。'''","link":"/2019/02/27/TensorFlow实战Google深度学习框架-笔记-第二、三章/"},{"title":"TensorFlow实战Google深度学习框架 笔记 第四章","text":"去线性化TensorFlow提供七种非线性激活函数，tf.nn.relu, tf.sigmoid, tf.tanh最为常见。 加入偏置项和激活函数的神经网络结构图 以下代码展示了上述前向传播实现过程。 12a = tf.nn.relu(tf.matmul(x, w1) + biases1)y = tf.nn.relu(tf.matmul(a, w2) + biases2) 损失函数经典损失函数分类问题和回归问题是监督学习的两大种类。 分类问题交叉熵 $H(p,q)$ 描述了通过概率 $q$ 表达概率 $p$ 的困难程度，值越小表示越容易。 $$H(p,q)= -\\sum_{x}p(x)\\log q(x)$$ softmax回归将一个$n$维数据转换为一组满足概率分布条件的数值。 $$softmax(y)_i=y’_i=\\frac{e^{y_i}}{\\sum^n_{j=1}e^{y_j}}$$ 交叉熵代码示例 12# 以y_表示正确结果，y表示预测结果cross_entropy = -tf.reduce_mean(y_ * tf.log(tf.clip_by_value(y, 1e-10, 1.0))) 其中: tf.clip_by_value函数可以将一个张量中的数值限制在一个范围之内避免一些运算错误（比如 log0 是无效的）。 123v = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])print tf.clip_by_value(v, 2.5, 4.5).eval()# 输出 [[2.5 2.5 3.] [4. 4.5 4.5]] tf.log函数对张量中所有元素依次求对数。 123v = tf.constant([1.0, 2.0, 3.0])print tf.log(v).eval()# 输出［0. 0.69314718 1.09861231] 矩阵元素对应相乘用”*“，矩阵作矩阵乘法用tf.matmul 123456v1 = tf.constant([[1.0, 2.0], [3.0, 4.0]])v2 = tf.constant([[5.0, 6.0], [7.0, 8.0]])print (v1 * v2).eval()# 输出 [[5. 12.] [ 21. 32.]]print tf.matmul(v1, v2).eval()# 输出 [[19. 22.] [ 43. 50.]] tf.reduce_mean求均值 123v = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])print tf.reduce_mean(v).eval()# 输出值为3.5 交叉煽一般会与 softmax 回归一起使用，可以直接通过以下代码来实现使用了 softmax 回归之后的交叉熵损失函数： 12cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels = y_, logits=y) 以上 y 代表了原始神经网络的输出结果，而 y_ 给出了标准答案。 回归问题与分类问题不同，回归问题解决的是对具体数值的预测。对于回归问题，最常用的损失函数是均方误差 (MSE, mean squared error)。定义如下： $$MSE(y,y’)=\\frac{\\sum_{i=1}^n(y_i-y’_i)^2}n$$ 其中$y_i$为一个batch中第i个数据的正确答案，而$y_i’$ 为神经网络给出的预测值。代码实现 12mse = tf.reduce_mean(tf.square(y_ - y))# y代表了神经网络的输出答案， y_代表了标准答案。 自定义损失函数例如(书上p79): $$Loss(y, y’)=\\sum^n_{i=1}f(y_i, y’_i)$$ $$f(x,y)=\\begin{cases}{a(x-y)} &amp; {x &gt; y} \\{b(y-x)} &amp; {x \\le y}\\end{cases}$$ 代码实现： 1loss = tf.reduce_sum(tf.where(tf.greater(v1, v2), (v1 - v2) * a, (v2 - v1) * b)) tf.greater会比较这两个输入张量中每一个元素的大小，并返回比较结果 。tf.where函数有三个参数。第一个为选择条件根据， 当选择条件为 True 时，tf.where 函数会选择第二个参数中的值， 否则使用第三个参数中的值。代码示例： 123456789import tensorflow as tfv1 = tf.constant([1.0, 2.0, 3.0, 4.0])v2 = tf.constant([4.0, 3.0, 2.0, 1.0])sess = tf.InteractiveSession()print tf.greater(v1, v2).eval()# 输出 [False False True True]print tf.where(tf.greater(v1, v2), v1, v2).eval()# 输出[4. 3. 3. 4.]sess.close() 使用自定义的损失函数进行神经网络训练的示例代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147import tensorflow as tffrom numpy.random import RandomState# 定义神经网络的相关参数和变量。batch_size = 8x = tf.placeholder(tf.float32, shape=(None, 2), name=\"x-input\")y_ = tf.placeholder(tf.float32, shape=(None, 1), name='y-input')w1= tf.Variable(tf.random_normal([2, 1], stddev=1, seed=1))y = tf.matmul(x, w1)# 定义损失函数使得预测少了的损失大，于是模型应该偏向多的方向预测。loss_less = 10loss_more = 1loss = tf.reduce_sum(tf.where(tf.greater(y, y_), (y - y_) * loss_more, (y_ - y) * loss_less))train_step = tf.train.AdamOptimizer(0.001).minimize(loss)# 生成模拟数据集rdm = RandomState(1)X = rdm.rand(128,2)Y = [[x1+x2+(rdm.rand()/10.0-0.05)] for (x1, x2) in X]#训练模型。with tf.Session() as sess: init_op = tf.global_variables_initializer() sess.run(init_op) STEPS = 5000 for i in range(STEPS): start = (i*batch_size) % 128 end = (i*batch_size) % 128 + batch_size sess.run(train_step, feed_dict={x: X[start:end], y_: Y[start:end]}) if i % 1000 == 0: print(\"After %d training step(s), w1 is: \" % (i)) print sess.run(w1), \"\\n\" print \"Final w1 is: \\n\", sess.run(w1)'''After 0 training step(s), w1 is: [[-0.81031823] [ 1.4855988 ]] After 1000 training step(s), w1 is: [[ 0.01247112] [ 2.1385448 ]] After 2000 training step(s), w1 is: [[ 0.45567414] [ 2.17060661]] After 3000 training step(s), w1 is: [[ 0.69968724] [ 1.8465308 ]] After 4000 training step(s), w1 is: [[ 0.89886665] [ 1.29736018]] Final w1 is: [[ 1.01934695] [ 1.04280889]]'''#重新定义损失函数，使得预测多了的损失大，于是模型应该偏向少的方向预测。loss_less = 1loss_more = 10loss = tf.reduce_sum(tf.where(tf.greater(y, y_), (y - y_) * loss_more, (y_ - y) * loss_less))train_step = tf.train.AdamOptimizer(0.001).minimize(loss)with tf.Session() as sess: init_op = tf.global_variables_initializer() sess.run(init_op) STEPS = 5000 for i in range(STEPS): start = (i*batch_size) % 128 end = (i*batch_size) % 128 + batch_size sess.run(train_step, feed_dict={x: X[start:end], y_: Y[start:end]}) if i % 1000 == 0: print(\"After %d training step(s), w1 is: \" % (i)) print sess.run(w1), \"\\n\" print \"Final w1 is: \\n\", sess.run(w1)'''After 0 training step(s), w1 is: [[-0.81231821] [ 1.48359871]] After 1000 training step(s), w1 is: [[ 0.18643527] [ 1.07393336]] After 2000 training step(s), w1 is: [[ 0.95444274] [ 0.98088616]] After 3000 training step(s), w1 is: [[ 0.95574027] [ 0.9806633 ]] After 4000 training step(s), w1 is: [[ 0.95466018] [ 0.98135227]] Final w1 is: [[ 0.95525807] [ 0.9813394 ]]'''#定义损失函数为MSE。loss = tf.losses.mean_squared_error(y, y_)train_step = tf.train.AdamOptimizer(0.001).minimize(loss)with tf.Session() as sess: init_op = tf.global_variables_initializer() sess.run(init_op) STEPS = 5000 for i in range(STEPS): start = (i*batch_size) % 128 end = (i*batch_size) % 128 + batch_size sess.run(train_step, feed_dict={x: X[start:end], y_: Y[start:end]}) if i % 1000 == 0: print(\"After %d training step(s), w1 is: \" % (i)) print sess.run(w1), \"\\n\" print \"Final w1 is: \\n\", sess.run(w1)'''After 0 training step(s), w1 is: [[-0.81031823] [ 1.4855988 ]] After 1000 training step(s), w1 is: [[-0.13337609] [ 1.81309223]] After 2000 training step(s), w1 is: [[ 0.32190299] [ 1.52463484]] After 3000 training step(s), w1 is: [[ 0.67850214] [ 1.25297272]] After 4000 training step(s), w1 is: [[ 0.89473999] [ 1.08598232]] Final w1 is: [[ 0.97437561] [ 1.0243336 ]]''' 神经网络优化算法神经网络大致遵循以下过程： 12345678910111213141516171819batch_size = n# 每次读取一小部分数据作为当前的训练数据来执行反向传播算法。x = tf.placeholder(...)y_ = tf.placeholder(...)# 定义神经网络结构和优化算法。loss = ...train_step = tf.train.AdamOptimizer(0.001).minimize(loss)# 训练with tf.Session() as sess: # 参数初始化 ... # 迭代跟新参数 for i in range(STEPS): # 准备 batch_size 个训练数据。一般将所有训练数据随机打乱之后再选取可以得到更好的优化效果。 current_X, current_Y = ... sess.run(train_step, feed_dict={x: current_X, y_: current_Y}) 神经网络进一步优化学习率tf.train.exponential_decay 函数实现了指数衰减学习率，实现了以下代码功能： 12decayed_learning_rate = \\ learning_rate * decay_rate ^ (global_step / decay_steps) decayed_learning_rate 为每一轮优化时使用的学习率 learning_rate 为事先设定的初始学习率 decay_rate 为衰减系数 decay_steps 为衰减速度 tf.train.exponential_decay 函数可以通过设置参数 staircase 选择不同的衰减方式。 staircase 的默认值为 False。当 staircase 的值被设置为 True 时， global_step /decay_steps 会被转化成整数。这使得学习率成为一个阶梯函数（ staircase function ），如下图所示： 指数衰减学习率随着法代轮数的变化图 tf.train.exponential_decay 示例： 123456789global step = tf.Variable(O)# 通过 exponential_decay 函数生成学习率。learning_rate = tf.train.exponential_decay(0.1, global_step, 100, 0.96, staircase=True)# 使用指数衰减的学习率。在 minimize 函数中传入 global_step 将自动更新# global_step 参数，从而使得学习率也得到相应更新。learning_step = tf.train.GradientDescentOptimizer(learning_rate)\\.minimize( ... my loss ... , global_step = global_step) 过拟合问题L1 正则化会让参数变得更稀疏，而 L2 正则化不会。L2 正则化不会让参数变得稀疏的原因是当参数很小时，比如 0.001 ，这个参数的平方基本上就可以忽略了，于是模型不会进一步将这个参数调整为 0。其次，L1 正则化的计算公式不可导，而 L2 正则化公式可导。带 L2 正则化的损失函数定义： 1234w = tf.Variable(tf.random_normal([2, 1), stddev=1, seed=1))y = tf.matmul(x, w)loss = tf.reduce_mean(tf.square(y_ - y)) + tf.contrib.layers.12_regularizer(lambda) (w) lambda 参数表示了正则化项的权重。 TensorFlow 提供:tf.contrib.layers.l1_regularizer 可以计算 L1 正则化项的值。tf.contrib.layers.l2_regularizer 可以计算 L2 正则化项的值。以下为两个正则化的计算实例： 12345678weights = tf.constant([[1.0, -2.0], [-3.0, 4.0]])with tf.Session() as sess: ＃输出为(|1|+|-2|+|-3|+|4|)×0.5=5。其中 0.5 为正则化项的权重。 print sess.run(tf.contrib.layers.11_regularizer(.5)(weights)) ＃输出为(1*1 + (-2)*(-2) + (-3)*(-3) + 4*4)/2×0.5=7.5 #TensorFlow 会将L2的正则化损失值除以 2 使得求导得到的结果更加简洁 。 print sess.run(tf.contrib.layers.12_regularizer(.5)(weights)) 可以使用 TensorFlow 中提供的集合 (collention) 解决训练参数增多后更加复杂的问题。以下代码给出了通过集合计算一个 5 层神经网络带 L2 正则化的损失函数的计算方法。 12345678910111213141516171819202122232425# 生成模拟数据集。import tensorflow as tfimport matplotlib.pyplot as pltimport numpy as npdata = []label = []np.random.seed(0)# 以原点为圆心，半径为1的圆把散点划分成红蓝两部分，并加入随机噪音。for i in range(150): x1 = np.random.uniform(-1,1) x2 = np.random.uniform(0,2) if x1**2 + x2**2 &lt;= 1: data.append([np.random.normal(x1, 0.1),np.random.normal(x2,0.1)]) label.append(0) else: data.append([np.random.normal(x1, 0.1), np.random.normal(x2, 0.1)]) label.append(1) data = np.hstack(data).reshape(-1,2)label = np.hstack(label).reshape(-1, 1)plt.scatter(data[:,0], data[:,1], c=label, cmap=\"RdBu\", vmin=-.2, vmax=1.2, edgecolor=\"white\")plt.show() 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879# 定义一个获取权重，并自动加入正则项到损失的函数。def get_weight(shape, lambda1): var = tf.Variable(tf.random_normal(shape), dtype=tf.float32) tf.add_to_collection('losses', tf.contrib.layers.l2_regularizer(lambda1)(var)) return var# 定义神经网络。x = tf.placeholder(tf.float32, shape=(None, 2))y_ = tf.placeholder(tf.float32, shape=(None, 1))sample_size = len(data)# 每层节点的个数layer_dimension = [2,10,5,3,1]n_layers = len(layer_dimension)cur_layer = xin_dimension = layer_dimension[0]# 循环生成网络结构for i in range(1, n_layers): out_dimension = layer_dimension[i] weight = get_weight([in_dimension, out_dimension], 0.003) bias = tf.Variable(tf.constant(0.1, shape=[out_dimension])) cur_layer = tf.nn.elu(tf.matmul(cur_layer, weight) + bias) in_dimension = layer_dimension[i]y= cur_layer# 损失函数的定义。mse_loss = tf.reduce_sum(tf.pow(y_ - y, 2)) / sample_sizetf.add_to_collection('losses', mse_loss)loss = tf.add_n(tf.get_collection('losses'))# 训练不带正则项的损失函数mse_loss。# 定义训练的目标函数mse_loss，训练次数及训练模型train_op = tf.train.AdamOptimizer(0.001).minimize(mse_loss)TRAINING_STEPS = 40000with tf.Session() as sess: tf.global_variables_initializer().run() for i in range(TRAINING_STEPS): sess.run(train_op, feed_dict={x: data, y_: label}) if i % 2000 == 0: print(\"After %d steps, mse_loss: %f\" % (i,sess.run(mse_loss, feed_dict={x: data, y_: label}))) # 画出训练后的分割曲线 xx, yy = np.mgrid[-1.2:1.2:.01, -0.2:2.2:.01] grid = np.c_[xx.ravel(), yy.ravel()] probs = sess.run(y, feed_dict={x:grid}) probs = probs.reshape(xx.shape)plt.scatter(data[:,0], data[:,1], c=label, cmap=\"RdBu\", vmin=-.2, vmax=1.2, edgecolor=\"white\")plt.contour(xx, yy, probs, levels=[.5], cmap=\"Greys\", vmin=0, vmax=.1)plt.show()'''After 0 steps, mse_loss: 22.745703After 2000 steps, mse_loss: 0.061583After 4000 steps, mse_loss: 0.049916After 6000 steps, mse_loss: 0.040501After 8000 steps, mse_loss: 0.032112After 10000 steps, mse_loss: 0.025778After 12000 steps, mse_loss: 0.019642After 14000 steps, mse_loss: 0.016576After 16000 steps, mse_loss: 0.014309After 18000 steps, mse_loss: 0.012851After 20000 steps, mse_loss: 0.011881After 22000 steps, mse_loss: 0.011130After 24000 steps, mse_loss: 0.010511After 26000 steps, mse_loss: 0.010117After 28000 steps, mse_loss: 0.009695After 30000 steps, mse_loss: 0.009219After 32000 steps, mse_loss: 0.008900After 34000 steps, mse_loss: 0.008421After 36000 steps, mse_loss: 0.007951After 38000 steps, mse_loss: 0.007678''' 123456789101112131415161718192021222324252627282930313233343536373839404142434445# 训练带正则项的损失函数loss。# 定义训练的目标函数loss，训练次数及训练模型train_op = tf.train.AdamOptimizer(0.001).minimize(loss)TRAINING_STEPS = 40000with tf.Session() as sess: tf.global_variables_initializer().run() for i in range(TRAINING_STEPS): sess.run(train_op, feed_dict={x: data, y_: label}) if i % 2000 == 0: print(\"After %d steps, loss: %f\" % (i, sess.run(loss, feed_dict={x: data, y_: label}))) # 画出训练后的分割曲线 xx, yy = np.mgrid[-1:1:.01, 0:2:.01] grid = np.c_[xx.ravel(), yy.ravel()] probs = sess.run(y, feed_dict={x:grid}) probs = probs.reshape(xx.shape)plt.scatter(data[:,0], data[:,1], c=label, cmap=\"RdBu\", vmin=-.2, vmax=1.2, edgecolor=\"white\")plt.contour(xx, yy, probs, levels=[.5], cmap=\"Greys\", vmin=0, vmax=.1)plt.show()'''After 0 steps, loss: 4.712693After 2000 steps, loss: 0.143827After 4000 steps, loss: 0.111660After 6000 steps, loss: 0.085316After 8000 steps, loss: 0.066900After 10000 steps, loss: 0.060303After 12000 steps, loss: 0.059699After 14000 steps, loss: 0.059239After 16000 steps, loss: 0.058850After 18000 steps, loss: 0.058719After 20000 steps, loss: 0.058361After 22000 steps, loss: 0.058352After 24000 steps, loss: 0.058352After 26000 steps, loss: 0.058351After 28000 steps, loss: 0.058351After 30000 steps, loss: 0.058351After 32000 steps, loss: 0.058351After 34000 steps, loss: 0.058350After 36000 steps, loss: 0.058350After 38000 steps, loss: 0.058351''' 以上，tf.get_collection(‘losses’)返回一个列表，这个列表是所有这个集合中的元素。这些元素就是损失函数的不同部分，将它们加起来就可以得到最终的损失函数。 滑动平均模型TensorFlow 中提供了tf.train.ExponentialMovingAverage 来实现滑动平均模型, 它对每一个变量会维护一个影子变量 ( shadow variable )，这个影子变量的初始值就是相应变量的初始值，而每次运行变量更新时，影子变量的值会更新为 ：shadow_variable = decay × shadow_variable + (1 - decay) × variable其中 shadow_ variable 为影子变量， variable 为待更新的变量，decay 为衰减率。如果在 ExponentialMovingAverage 初始化时提供了 num_updates 参数，那么每次使用的衰减率将是 ： $$min{decay, \\frac{1 + num_updates}{10+num_updates}}$$ 示例代码： 12345678910111213141516171819202122232425262728293031323334353637import tensorflow as tf# 定义变量及滑动平均类v1 = tf.Variable(0, dtype=tf.float32)step = tf.Variable(0, trainable=False)ema = tf.train.ExponentialMovingAverage(0.99, step)maintain_averages_op = ema.apply([v1])# 查看不同迭代中变量取值的变化。with tf.Session() as sess: # 初始化 init_op = tf.global_variables_initializer() sess.run(init_op) print sess.run([v1, ema.average(v1)]) # 更新变量v1的取值 sess.run(tf.assign(v1, 5)) sess.run(maintain_averages_op) print sess.run([v1, ema.average(v1)]) # 更新step和v1的取值 sess.run(tf.assign(step, 10000)) sess.run(tf.assign(v1, 10)) sess.run(maintain_averages_op) print sess.run([v1, ema.average(v1)]) # 更新一次v1的滑动平均值 sess.run(maintain_averages_op) print sess.run([v1, ema.average(v1)])'''[0.0, 0.0][5.0, 4.5][10.0, 4.5549998][10.0, 4.6094499]''' 为了提高笔记效率，部分代码引用自网络，链接：https://github.com/caicloud/tensorflow-tutorial/blob/master/Deep_Learning_with_TensorFlow/1.4.0/Chapter04/","link":"/2019/03/01/TensorFlow实战Google深度学习框架-笔记-第四章/"}],"tags":[{"name":"语言","slug":"语言","link":"/tags/语言/"},{"name":"英语","slug":"英语","link":"/tags/英语/"},{"name":"test","slug":"test","link":"/tags/test/"},{"name":"深度学习","slug":"深度学习","link":"/tags/深度学习/"},{"name":"TensorFlow","slug":"TensorFlow","link":"/tags/TensorFlow/"}],"categories":[{"name":"语言","slug":"语言","link":"/categories/语言/"},{"name":"testct1","slug":"testct1","link":"/categories/testct1/"},{"name":"英语","slug":"语言/英语","link":"/categories/语言/英语/"},{"name":"testct2","slug":"testct1/testct2","link":"/categories/testct1/testct2/"},{"name":"读书笔记","slug":"读书笔记","link":"/categories/读书笔记/"},{"name":"TensorFlow实战Google深度学习框架","slug":"读书笔记/TensorFlow实战Google深度学习框架","link":"/categories/读书笔记/TensorFlow实战Google深度学习框架/"}]}